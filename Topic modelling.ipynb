{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag, pos_tag_sents\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import gensim.models.ldamodel as ldamodel\n",
    "from gensim.summarization import summarize\n",
    "import pyLDAvis.gensim\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.probability import FreqDist\n",
    "from IPython.utils.text import columnize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import textwrap\n",
    "%matplotlib notebook\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>Region Name</th>\n",
       "      <th>Country or Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989</td>\n",
       "      <td>MDV</td>\n",
       "      <td>﻿It is indeed a pleasure for me and the member...</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Maldives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989</td>\n",
       "      <td>FIN</td>\n",
       "      <td>﻿\\nMay I begin by congratulating you. Sir, on ...</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989</td>\n",
       "      <td>NER</td>\n",
       "      <td>﻿\\nMr. President, it is a particular pleasure ...</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Niger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989</td>\n",
       "      <td>URY</td>\n",
       "      <td>﻿\\nDuring the debate at the fortieth session o...</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>﻿I should like at the outset to express my del...</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year country                                               text  \\\n",
       "0  1989     MDV  ﻿It is indeed a pleasure for me and the member...   \n",
       "1  1989     FIN  ﻿\\nMay I begin by congratulating you. Sir, on ...   \n",
       "2  1989     NER  ﻿\\nMr. President, it is a particular pleasure ...   \n",
       "3  1989     URY  ﻿\\nDuring the debate at the fortieth session o...   \n",
       "4  1989     ZWE  ﻿I should like at the outset to express my del...   \n",
       "\n",
       "  Region Name Country or Area  \n",
       "0        Asia        Maldives  \n",
       "1      Europe         Finland  \n",
       "2      Africa           Niger  \n",
       "3    Americas         Uruguay  \n",
       "4      Africa        Zimbabwe  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#source of iso code database: https://unstats.un.org/unsd/methodology/m49/overview/\n",
    "##The dataset represents country names as 3-letter ISO-alpha3 Codes.\n",
    "# To convert these codes into country names, I merged df with UN country names\n",
    "# This dataset also specifies the region (continent), which I will need later.\n",
    "\n",
    "df = pd.read_csv('un-general-debates.csv').drop('session', axis=1)\n",
    "country_names = pd.read_excel('UNSD — Methodology.xlsx')\n",
    "df = pd.merge(df, country_names[['Region Name','Country or Area','ISO-alpha3 Code']],\n",
    "             how='left', left_on='country', right_on='ISO-alpha3 Code')\n",
    "df.drop('ISO-alpha3 Code',axis=1, inplace=True) #removing a duplicate column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing texts for analysis:\n",
    "def preprocessText(text):\n",
    "    text = re.sub('[^a-z]+',' ', text.lower()) # remove all non-letter characters\n",
    "    tokens = word_tokenize(text) # returns a list of individual words\n",
    "    # Removing unhelpfull, ubiquitous words ('stop words', e.g. ‘the’, ‘is’, ‘are’):\n",
    "    tokens = [token for token in tokens if len(token) > 4 and\n",
    "             token not in nltk.corpus.stopwords.words('english')]\n",
    "    # Lemmatizing removes inflectional endings and gets the root word (lemma):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmas\n",
    "\n",
    "# processed text as list of lemmas:\n",
    "df['lemmatized_tokens'] = df['text'].apply(preprocessText)\n",
    "# processed text in continous form:\n",
    "df['lemmatized_text'] = [' '.join(x) for x in df['lemmatized_tokens']]\n",
    "# calculating the number of times each words appears in a speech:\n",
    "df['freq_dist'] = df['lemmatized_tokens'].apply(FreqDist)\n",
    "df[['text','lemmatized_tokens','lemmatized_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
